# 14-03. 페이지 교체와 프레임 할당
- 가상 메모리를 통해 작은 물리 메모리보다 큰 프로세스도 실행할 수 있다고는 하지만, 여전히 물리 메모리의 크기는 한정되어 있다. 
- 운영체제는 프로세스들이 한정된 메모리를 효율적으로 이용할 수 있도록 기존 메모리에 적재된 불필요한 페이지 선별 후 보조기억장치로 내보낼 수 있어야 하고, 프로세스들에 적절한 수의 프레임을 할당하여
페이지를 할당할 수 있게 해야 한다.
- 이를 위해 요구 페이징, 페이지 교체 알고리즘, 프레임 할당에 대해 알아보자.

## 요구 페이징
- 프로세스를 메모리에 적재할 때 처음부터 모든 페이지를 적재하지 않고 필요한 페이지만을 메모리에 적재하는 기법을 요구 페이징(demand paging)이라 한다. 이름 그대로 실행에 요구되는 페이지만
적재하는 기법
- 요구 페이징의 기본적인 양상
  1. CPU가 특정 페이지에 접근하는 명령어 실행
  2. 해당 페이지가 현재 메모리에 있을 경우 (유효 비트가 1) CPU는 페이지가 적재된 프레임에 접근
  3. 해당 페이지가 현재 메모리에 없을 경우 (유효 비트가 0) 페이지 폴트가 발생
  4. 페이지 폴트 처리 루틴은 해당 페이지를 메모리로 적재하고 유효 비트를 1로 설정
  5. 다시 1번 수행
- 참고로 아무런 페이지도 메모리에 적재하지 않은 채 무작정 실행부터 할 수도 있는데, 이 경우 프로세스의 첫 명령어를 실행하는 순간부터 페이지 폴트가 계속 발생, 실행에 필요한 페이지가 어느 정도
적재된 이후부터는 페이지 폴트 발생 빈도가 떨어진다. 이를 순수 요구 페이징(pure demand paging) 기법이라 한다.
- 위와 같은 요구 페이징 시스템이 안정적으로 작동하려면 필연적으로 페이지 교체, 프레임 할당을 해결해야 한다.
- 요구 페이징 기법으로 메모리 적재하다보면 언젠가 메모리가 가득 탐. 이때는 당장 실행에 필요한 페이지 적재 위해 메모리에 적재된 페이지를 보조기억장치로 내보내야 함. 메모리에 적재된 많고 많은
페이지 중 어떤 페이지를 내보내는 것이 최선인지 결정하는 방법이 페이지 교체 알고리즘이다. 즉, 쫓아낼 페이지를 결정하는 방법을 페이지 교체 알고리즘이라 함.

## 페이지 교채 알고리즘
- 일반적으로 페이지 폴트를 가장 적게 일으키는 알고리즘을 좋은 알고리즘으로 평가. 페이지 폴트가 일어나면 보조기억장치로부터 필요한 페이지를 가져와야 하기 때문에 메모리에 적재된 페이지를 가져오는
것보다 느려지기 때문.
- "한 페이지 교체 알고리즘을 선택했더니 페이지 폴트가 자주 발생했다"는 말은 "보조기억장치로 내쫓을 페이지를 잘못 골랐다"는 뜻으로, 내보내면 안 되는 페이지를 보조기억장치로 내보냈다는 의미와 같다.
이는 당연히 컴퓨터의 성능을 저해하는 나쁜 알고리즘일 것. 반면 어떤 알고리즘을 통해 고른 페이지를 스왑 아웃시켜도 페이지 폴트가 자주 발생하지 않는다면 이는 컴퓨터의 성능 저하를 방지하는 좋은
알고리즘으로 평가할 수 있다.
- 그렇게에 페이지 교체 알고리즘을 제대로 이해하려면 페이지 폴트 횟수를 알 수 있어야 한다. 그리고 페이지 폴트 횟수는 페이지 참조열(page reference string)을 통해 알 수 있다. CPU가 참조하는
페이지들 중 연속된 페이지를 생략한 페이지열을 의미한다. 예를 들어
```text
2 2 2 3 5 5 3 3 7
```
- 여기서 연속된 페이지를 생략한 페이지열, 다시 말해 아래 숫자열이 페이지 참조열
```text
2 3 5 3 7
```
- 연속된 페이지를 생략하는 이유는 중복된 페이지를 참조하는 행위는 페이지 폴트를 발생시키지 않기 때문. 페이지 교체 알고리즘을 평가할 때 관심있게 고려할 것은 오직 페이지 폴트의 발생 횟수이기 때문에
어차피 페이지 폴트가 일어나지 않을 연속된 페이지에 대한 참조는 고려하지 않는 것. 이제 대표적인 페이지 교체 알고리즘에 대해 하나씩 알아보고 페이지 참조열을 바탕으로 각 알고리즘의 성능을 평가하자.

### FIFO 페이지 교체 알고리즘 (First-In First-Out Page Replacement Algorithm)
- FIFO 페이지 교체 알고리즘은 가장 단순한 방법으로 메모리에 가장 먼저 올라온 페이지부터 내쫓는 방식, 즉, "오래 머물렀다면 나가라"는 알고리즘
- 예를 들어, 프레임 세 개에 페이지 참조열이 아래와 같다고 해보자.
```text
2 3 1 3 5 2 3 4 2 3
```
```text
2 | 2
3 | 2 3
1 | 2 3 1
3 | 2 3 1
5 | 5 3 1 // 폴트
2 | 5 2 1 // 폴트
3 | 5 2 3 // 폴트
4 | 4 2 3 // 폴트
2 | 4 2 3
3 | 4 2 3
```
- 페이지 초기에 페이지 폴트 제외하고 4번의 페이지 폴트가 일어난다.
- FIFO 페이지 교체 알고리즘은 아이디어와 구현이 간단하지만, 마냥 좋은 것은 아니다. 프로그램 실행 초기에 적재된 페이지 속에는 프로그램 실행 초기에 잠깐 실행되다가 이후에 사용되지 않을 페이지도
있겠지만, 프로그램 실행 내내 사용될 내용을 포함하고 있을 수도 있다. 이런 페이지는 메모리에 먼저 적재되었다고 해서 내쫓아서는 안 된다.

#### 2차 기회 페이지 교체 알고리즘 (second change page replacement algorithm)
- FIFO 페이지 교체 알고리즘은 자칫 자주 참조되는 페이지가 먼저 적재되었다는 이유만으로 내쫓길 수 있다는 문제가 있는데, 2차 기회 페이지 교체 알고리즘은 이러한 부작용을 어느 정도 개선한 FIFO
페이지 교체 알고리즘의 변형. 이름 그대로 한 번 더 기회를 주는 알고리즘.
- 2차 기회 페이지 교체 알고리즘은 FIFO 페이지 교체 알고리즘과 같이 기본적으로 메모리에서 가장 오래 머물렀던 페이지를 대상으로 내보낼 페이지 선별. 차이가 이싸면 만일 페이지의 참조 비트가 1일
경우, 당장 내쫓지 ㅇ낳고 참조 비트를 0으로 만든 뒤 현재 시간을 적재 시간으로 설정. 메모리에 가장 오래 머물렀다고 할지라도 참조 비트가 1이라는 의미는 CPU가ㅓ 접근한 적이 있으므 로, 한 번 더
기회를 주는 셈. 메모리에 가장 오래 머무른 페이지의 참조 비트가 0일 경우 이 페이지는 가장 오래된 페이지이면서 동시에 사용되지 않은 페이지라고 볼 수 있다.

### 최적 페이지 교체 알고리즘 (optimal page replacement algorithm)
- 최적 페이지 교체 알고리즘은 CPU에 의해 참조되는 횟수를 고려하는 페이지 교체 알고리즘. 
- 보조기억장치로 내보내야 할 페이지는 앞으로 사용 빈도가 가장 낮은 페이지이므로, 앞으로의 사용 빈도가 가장 낮은 페이지를 교체하는 알고리즘을 페이지 교체 알고리즘으로 삼는 것이 가장 합리적.
이 알고리즘이 최적 페이지 최적 페이지 교체 알고리즘.
- 프레임 세 개에 페이지 참조열이 아래와 같을 때 예시를 보자.
```text
2 3 1 3 5 2 3 4 2 3
```
```text
2 | 2
3 | 2 3
1 | 2 3 1
3 | 2 3 1
5 | 2 3 5 // 폴트
2 | 2 3 5
3 | 2 3 5
4 | 2 3 4 // 폴트
2 | 2 3 4
3 | 2 3 4
```
- 총 두 번의 페이지 폴트가 발생. FIFO 알고리즘에 비해 페이지 폴트 빈도가 훨씬 낮아졌다.
- 최적 페이지 교체 알고리즘은 이름 그대로 가장 낮은 페이지 폴트율을 보장하는 알고리즘이다. 다른 알고리즘과 비교해도 그렇다. 
- 다만, 최적 페이지 교체 알고리즘은 실제 구현이 어렵다. 최적 페이지 교체 알고리즘은 앞으로 오랫동안 사용되지 않을 페이지를 내보내는 알고리즘인데, 예측하기란 사실상 불가능에 가깝다. 
- 따라서, 최적 페이지 교체 알고리즘은 그 자체를 운영체제에서 사용하기보다는, 주로 다른 페이지 교체 알고리즘의 이론상 성능을 평가하기 위한 목적으로 사용됨.
- 즉, 최적 페이지 교체 알고리즘을 실행했을 때 발생하는 페이지 폴트 횟수를 페이지 폴트의 하한선으로 간주, 하한선에 비해 얼만큼 페이지 폴트 횟수가 발생하느냐를 통해 페이지 교체 알고리즘 평가.

### LRU 페이지 교체 알고리즘 (LRU; Least Recently Used Page Replacement Algorithm)
- 최적 페이지 교체 알고리즘은 구현은 어려워도 비슷한 알고리즘은 만들 수 있다. 가장 오랫동안 사용되지 '않을' 체이지를 교체하는 알고리즘 대신 오랫동안 사용되지 '않은' 페이지를 교체하는 알고리즘은
구현 가능. 이 알고리즘이 LRU 페이지 교체 알고리즘.
- '최근에 사용되지 않은 페이지는 앞으로도 사용되지 않을 것'이라는 아이디어를 토대로 만들어진 알고리즘으로 페이지마다 마지막으로 사용한 시간을 토애로 최근에 가장 사용이 적었던 페이지를 교체.

```text
2 3 1 3 5 2 3 4 2 3
```
```text
2 | 2
3 | 2 3
1 | 2 3 1
3 | 2 3 1
5 | 5 3 1 // 폴트
2 | 5 3 2 // 폴트
3 | 5 3 2
4 | 4 3 2 // 폴트
2 | 4 3 2
3 | 4 3 2
```
- 이외에도 페이지 교체 알고리즘의 종류는 매우 다양. 방금 보았던 LRU 페이지 교체 알고리즘만 하더라도 많은 파생 알고리즘이 있다. 다만 이 알고리즘을 왜 사용하는지, 무엇이 좋은 페이지 알고리즘인지,
대표적인 페이지 교체 알고리즘들의 기본적인 아이디어는 무엇인지를 이해하는 데 중점을 두자.

## 스레싱과 프레임 할당
- 페이지 폴트가 자주 발생하는 이유에 나쁜 페이지 교체 알고리즘만 있는 것은 아니다. 프로세스가 사용할 수 있는 프레임 수가 적어도 페이지 폴트는 자주 발생. (이것이 더 근본적인 이유). 반대로 
프로세스가 사용할 수 있는 프레임 수가 많으면 일반적으로 페이지 폴트 빈도 감소. 
- 극단적으로 프레임이 무한한 컴퓨터와 1개인 컴퓨터를 비교하면 전자는 페이지를 수용할 공간이 넉넉해 모든 프로세스의 페이지가 메모리에 적재되어 페이지 폴트 발생 빈도가 적지만, 후자는 새로운 페이지를
참조할 때마다 페이지 폴트가 발생.
- 이처럼 프레임이 부족하면 CPU는 페이지 폴트가 자주 발생할 수밖에 없어 실행의 맥이 끊기고, 결과적으로 CPU의 이용률도 떨어짐. CPU가 쉴새 없이 프로세스를 실행해야 컴퓨터 전체의 생산성도
올라갈 텐데, 페이지 교체에 너무 많은 시간을 쏟으면 당연히 성능에도 큰 악영향 초래.
- 이처럼 프로세스가 실제 실행되는 시간보다 페이징에 더 많은 시간을 소요해 성능이 저해되는 문제를 스레싱(thrashing)이라 한다.
- 메모리에서 동시 실행되는 프로세스의 수를 멀티프로그래밍의 정도(degree of multiprogramming)라고 한다. 멀티프로그래밍의 정도가 높다면 현재 메모리에는 많은 프로세스가 동시에 실행중이고,
낮다면 현재 메모리에는 적은 프로세스가 동시에 실행중이라고 이해하면 된다.
- 동시에 실행되는 프로세스의 수(멀티프로그래밍의 정도)를 늘린다고 CPU 이용률이 그에 비례해서 증가하는 것이 아니다. 동시에 실행되는 프로세스 수가 어느 정도 증가하면 CPU 이용률은 높아지지만,
필요 이상으로 늘리면 각 프로세스들이 사용할 수 있는 프레임 수가 적어지기 때문에 페이지 폴트가 지나치게 빈번히 발생하고, 이에 따라 CPU 이용률이 떨어져 전체적인 성능 저하 발생.
- 아무리 CPU의 성능이 뛰어나도 동시에 실행되는 프로세스를 수용할 물리 메모리가 너무 작다면 전체 컴퓨터의 성능이 안 좋아지는 이유는 이러한 이유 때문.
- 스래싱이 발생하는 근본적인 원인은 각 프로세스가 필요로 하는 최소한의 프레임 수가 보장되지 않았기 때문. 그렇기에 운영체제는 각 프로세스들이 무리 없이 실행하기 위한 최소한의 프레임 수를 파악하고
프로세스들에 적절한 수만큼 프레임을 할당해 줄 수 있어야 한다.

### 정적 할당 방식
- 우선 가장 단순한 형태의 프레임 할당 방식부은 모든 프로세스에 균등하게 프레임을 제공하는 방식으로 균등 할당(equal allocation)이라고 한다.
- 하지만 이는 그리 권장하는 방식이 아니다. 실행되는 프로세스들의 크기는 각기 다른데, 동일한 프레임 개수를 할당하는 것은 비합리적이다. 이에 따라 프로세스의 크기가 크면 프레임을 많이 할당하고
프로세스의 크기가 작으면 프레임을 적게 나눠 주는 방식을 비례 할당(proportional allocation)이라고 한다.
- 균등 할당과 비례 할당 방식은 프로세스의 실행 과정을 고려하지 않고 단순히 프로세스의 크기와 물리 메모리의 크기만 고려한 방식이라는 점에서 정적 할당 방식이라고도 한다.
- 비례 할당 또한 완벽한 방식은 아니다. 프로세스의 크기가 클지라도 막상 실행해보니 많은 프레임을 필요로 하지 않는 경우도 있고, 반대로 프로세스의 크기가 작아도 많은 프레임을 필요로 하는 경우가
있다. 즉, 하나의 프로세스가 실제로 얼마나 많은 프레임이 필요할지는 결국 실행해 봐야 아는 경우가 많다.

### 동적 할당 방식
- 프로세스를 실행하는 과정에서 배분할 프레임을 결정하는 방식에는 방식에는 크게 작업 집합 모델 (working set model)을 사용하는 방식과 페이지 폴트 빈도(PFF; Page-Fault Frequency)를
사용하는 방식이 있다. 이 두 방식은 프로세스의 실행을 보고 할당할 프레임 수를 결정한다는 점에서 동적 할당 방식이라고도 한다.
- 스래싱이 발생하는 이유는 빈번한 페이지 교체 때문. 그렇기에 작업 집합 모델 기반 프레임 할당 방식은 '프로세스가 일정 기간 동안 참조한 페이지 집합'을 기억하여 빈번한 페이지 교체를 방지한다.
- CPU가 메모리를 참조할 때에는 참조 지역성의 원리에 읙서해 주로 비슷한 구역을 집중적으로 참조. 한 프로세스가 100개의 페이지로 이루어졌다고 해서 100개를 모두 고르게 참조하는 것이 아니라,
특정 시간 동안에는 몇몇 개의 페이지 (정확히는 몇 개의 페이지 내 주소들)만을 집중적으로 참조하게 된다.
- 그렇다면 CPU가 특정 시간 동안 주로 참조한 페이지 개수만큼만 프레임을 할당하면 페이지 교체는 빈번하게 발생하지 않는다. 만약 CPU가 어떤 프로세스를 실행하는 동안 3초에 일곱 일곱 개의 페이지를
집중적으로 참조했다면 운영체제는 그 프로세스를 위해 그 순간만큼은 최소 일곱 개의 프레임을 할당하면 된다.
- 실행 중인 프로세스가 일정 시간 동안 참조한 페이지의 집합을 작업 집합(working set)이라고 한다. CPU가 과거에 주로 참조한 페이지를 작업 집합에 포함한다면 운영체제는 작업 집합의 크기만큼만
프레임을 할당해 주면 된다.
- 다음으로 페이지 폴트 빈도를 기반으로 한 프레임 할당을 알아보면 아래의 두 개의 가정에서 생겨난 아이디어이다. 어찌보면 당연한 이야기.
  1. 페이지 폴트율이 너무 높으면 그 프로세스는 너무 적은 프레임을 갖고 있다.
  2. 페이지 폴트율이 너무 낮으면 그 프로세스가 너무 많은 프레임을 갖고 있다.
- 이를 그래프로 그렸을 때 (임의로 적당히 페이지 폴트율의 상한선과 하한선을 그려본다), 만일 페이지 폴트율이 상한선보다 높아지면 그 프로세스는 너무 적은 프레임을 갖고 있다고 볼 수 있다.
이 경우 프레임을 더 할당해 주면 된다.
- 반대로 페이지 폴트율이 하한선보다 더 낮아지면 그 프로세스는 너무 많은 프레임을 갖고 있다고 볼 수 있다. 따라서 이 경우 다른 프로세스에 할당하기 위해 프레임을 회수한다.
- 즉, 페이지 폴트 빈도 기반 프레임 할당 방식은 페이지 폴트율에 상한선과 하한선을 정하고, 이 범위 안에서만 프레임을 할당하는 방식.

## 키워드 정리
- 요구 페이징은 페이지가 필요할 때에만 메모리에 적재하는 기법
- 페이지 교체 알고리즘에는 FIFO, 최적, LRU 페이지 교체 알고리즘 등이 있다
- 스래싱이란 지나치게 빈번한 페이지 교체로 인해 CPU 이용률이 낮아지는 문제를 뜻함
- 프레임 할당 방식에는 균등 할당과 비례 할당, 작업 집합 모델 기반과 페이지 폴트율 기반 프레임 할당 방식이 있다
